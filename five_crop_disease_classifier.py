# -*- coding: utf-8 -*-
"""five-crop-disease-classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/onyangowalterochieng/five-crop-disease-classifier.a1da1f93-fb55-45e1-baa5-3de702eff0ae.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250818/auto/storage/goog4_request%26X-Goog-Date%3D20250818T080400Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D879f93c40a324bbb4c22f1dc9c54f487303cce3aef8d760dc1d82d0846eefaba39b825572d7b914fe7e5196433445905d045d5bcad851bcfa8d11b2cdaa11c9fc92ea667a827358cae910f5f762e6ac6589ac58b75fcfe7b88280724a6082b4ae88c29c431297da4bdd73130cda3fcf51d2bb8c859b05994434681389a22acbfa18d19d55dbf036f15efe00fb58568350e935d7005fa5af5f9ad9a0624c855eb0be892358ba4bf1ec1531c3d185da4cd37fbb52001d8c4b3f7a3bb98d236d65078934a4c6b3d36ed16327e09c30229d95d2ed1dbbda2296aba0beb6cbcdf55425972ea4d28086c78188bf34eb8424906fda1166e6161cc9bed147f79ae589cc0
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
shubham2703_five_crop_diseases_dataset_path = kagglehub.dataset_download('shubham2703/five-crop-diseases-dataset')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        # print(os.path.join(dirname, filename))
        pass

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# train_corrected.py
import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense, Dropout, GlobalAveragePooling2D, Reshape, LSTM
)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import cv2

# ---------------- CONFIG ----------------
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 30
LEARNING_RATE = 1e-4
MAX_IMAGES_PER_CLASS = 150  # set to None or larger if you have memory
BASE_DIR = "/kaggle/input/five-crop-diseases-dataset/Crop Diseases Dataset/Crop Diseases/Crop___Disease"
MODEL_SAVE = "crop_disease_cnn_lstm_model.keras"
# ----------------------------------------

np.random.seed(42)
tf.random.set_seed(42)

def create_dataset(base_dir, max_per_class=None):
    X = []
    y_int = []
    class_names = []
    label_map = {}
    label_idx = 0

    print("Scanning folders in:", base_dir)
    crops = sorted(os.listdir(base_dir))

    for crop in crops:
        crop_path = os.path.join(base_dir, crop)
        if not os.path.isdir(crop_path):
            continue
        diseases = sorted(os.listdir(crop_path))
        for disease in diseases:
            disease_path = os.path.join(crop_path, disease)
            if not os.path.isdir(disease_path):
                continue
            class_name = f"{crop}_{disease}"
            class_names.append(class_name)
            label_map[class_name] = label_idx
            image_files = sorted(os.listdir(disease_path))
            if max_per_class and len(image_files) > max_per_class:
                image_files = np.random.choice(image_files, max_per_class, replace=False)
            print(f"Loading {len(image_files)} files for class {class_name}")
            for img_file in tqdm(image_files, desc=f"{class_name}"):
                img_path = os.path.join(disease_path, img_file)
                if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                img = cv2.imread(img_path)
                if img is None:
                    continue
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
                img = img.astype('float32') / 255.0
                X.append(img)
                y_int.append(label_idx)
            label_idx += 1

    X = np.array(X, dtype=np.float32)
    y_int = np.array(y_int, dtype=np.int32)
    y_onehot = tf.keras.utils.to_categorical(y_int, num_classes=len(class_names))

    print("Total images:", X.shape[0], "Total classes:", len(class_names))
    return X, y_int, y_onehot, class_names, label_map

# Build dataset
X, y_int, y_onehot, class_names, label_map = create_dataset(BASE_DIR, max_per_class=MAX_IMAGES_PER_CLASS)

# Save class mapping for later inference
np.save("class_names.npy", np.array(class_names))
print("Saved class_names.npy")

# Split (use y_int for stratify)
X_train, X_temp, y_train_int, y_temp_int = train_test_split(
    X, y_int, test_size=0.3, random_state=42, stratify=y_int
)
X_val, X_test, y_val_int, y_test_int = train_test_split(
    X_temp, y_temp_int, test_size=0.5, random_state=42, stratify=y_temp_int
)

print("Train:", len(X_train), "Val:", len(X_val), "Test:", len(X_test))

# Compute class weights (for the integer labels)
class_weights_raw = compute_class_weight("balanced", classes=np.unique(y_train_int), y=y_train_int)
class_weight = {i: float(w) for i, w in enumerate(class_weights_raw)}
print("Class weights:", class_weight)

# Data augmentation for training generator
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.12,
    height_shift_range=0.12,
    shear_range=0.12,
    zoom_range=0.12,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Build model (MobileNetV2 backbone + GAP + reshape + LSTM head)
def build_cnn_lstm_model(input_shape, num_classes, learning_rate=LEARNING_RATE):
    base = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')
    base.trainable = False  # freeze for initial training

    model = Sequential()
    model.add(base)
    model.add(GlobalAveragePooling2D())

    # explicit feature size for reshape (channels of base output)
    feature_dim = base.output_shape[-1]
    model.add(Reshape((1, feature_dim)))

    # LSTM head (unusual but kept as requested)
    model.add(LSTM(256, return_sequences=True))
    model.add(Dropout(0.5))
    model.add(LSTM(128))
    model.add(Dropout(0.5))

    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss='sparse_categorical_crossentropy',  # use sparse so we can supply integer labels and class_weight
        metrics=['accuracy']
    )
    return model

num_classes = len(class_names)
model = build_cnn_lstm_model((IMG_SIZE, IMG_SIZE, 3), num_classes)
model.summary()

# Callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),
    ModelCheckpoint("best_crop_disease_model.keras", monitor='val_accuracy', save_best_only=True)
]

# Training generator (y needs to be integers because loss is sparse)
train_generator = train_datagen.flow(X_train, y_train_int, batch_size=BATCH_SIZE, shuffle=True)

steps_per_epoch = math.ceil(len(X_train) / BATCH_SIZE)
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=EPOCHS,
    validation_data=(X_val, y_val_int),
    callbacks=callbacks,
    class_weight=class_weight
)

# Save final model
model.save(MODEL_SAVE)
print("Saved model:", MODEL_SAVE)

# Evaluate
test_loss, test_acc = model.evaluate(X_test, y_test_int)
print("Test accuracy:", test_acc)

# Predictions and reports
y_pred = model.predict(X_test, batch_size=32)
y_pred_int = np.argmax(y_pred, axis=1)

print("\nClassification report:")
print(classification_report(y_test_int, y_pred_int, target_names=class_names))

# Confusion matrix
cm = confusion_matrix(y_test_int, y_pred_int)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.title("Confusion Matrix")
plt.show()

import tensorflow as tf

model = tf.keras.models.load_model("crop_disease_cnn_lstm_model.keras", compile=False)

model.save("crop_disease_cnn_lstm_model_v3.keras", save_format="keras")

import io, os, numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import tensorflow as tf

MODEL_PATH = "crop_disease_cnn_lstm_model.keras"
CLASS_NAMES_PATH = "class_names.npy"
IMG_SIZE = 224
print("Loading model (this may take a moment)...")
model = tf.keras.models.load_model(MODEL_PATH)
class_names = np.load(CLASS_NAMES_PATH, allow_pickle=True)
print("Loaded model and", len(class_names), "classes.")

import cv2
from IPython.display import display, HTML

def pil_to_rgb_array(pil_img):
    """Convert PIL image to HxWx3 RGB numpy array."""
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    return np.asarray(pil_img)

def decode_bytes_to_rgb(raw_bytes):
    """Try PIL and OpenCV decoding from raw bytes, return RGB numpy array or None."""
    try:
        pil = Image.open(io.BytesIO(raw_bytes)).convert("RGB")
        return pil_to_rgb_array(pil)
    except Exception:
        pass
    try:
        arr = np.frombuffer(raw_bytes, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            return img
    except Exception:
        pass
    return None

def preprocess_rgb_array(img_rgb, img_size=IMG_SIZE):
    """Resize and normalize to the form model expects."""
    pil = Image.fromarray(img_rgb)
    pil = pil.resize((img_size, img_size))
    arr = np.asarray(pil).astype("float32") / 255.0
    return arr

def predict_image_rgb(img_rgb, top_k=3):
    """Given an RGB numpy image, return top_k predictions (label, confidence)."""
    x = preprocess_rgb_array(img_rgb)
    preds = model.predict(np.expand_dims(x, 0))[0]
    topk_idx = preds.argsort()[-top_k:][::-1]
    return [(int(i), class_names[int(i)], float(preds[int(i)])) for i in topk_idx]

from ipywidgets import FileUpload, Button, HBox, VBox, Output, Label
from IPython.display import display, clear_output
import matplotlib.pyplot as plt

uploader = FileUpload(accept='.jpg,.jpeg,.png', multiple=False)
btn = Button(description="Predict", button_style="primary")
out = Output(layout={'border': '1px solid black'})
status = Label(value="Upload an image and click Predict")

def extract_uploaded_items(uploader_value):
    """
    Normalize uploader.value into a list of (filename, content_bytes).
    Handles dict, list, tuple shapes returned by various notebook/environments.
    """
    items = []
    v = uploader_value
    if not v:
        return items

    if isinstance(v, dict):
        for name, meta in v.items():
            if isinstance(meta, dict) and 'content' in meta:
                items.append((name, meta['content']))
            else:
                items.append((name, meta))
        return items

    if isinstance(v, (list, tuple)):
        for entry in v:
            if isinstance(entry, tuple) and len(entry) >= 2 and isinstance(entry[0], str):
                name = entry[0]
                content = entry[1]
                if isinstance(content, dict) and 'content' in content:
                    content = content['content']
                items.append((name, content))
            elif isinstance(entry, dict):
                name = entry.get('name') or entry.get('filename') or (list(entry.keys())[0] if entry.keys() else "uploaded")
                content = entry.get('content') or entry.get('data') or None
                if content is None:
                    if len(entry) == 1:
                        k = list(entry.keys())[0]
                        v2 = entry[k]
                        if isinstance(v2, dict) and 'content' in v2:
                            items.append((k, v2['content']))
                            continue
                if content is not None:
                    items.append((name, content))
        return items

    return items

def on_predict_clicked(b):
    with out:
        clear_output()
        val = uploader.value
        items = extract_uploaded_items(val)
        if len(items) == 0:
            print("No file uploaded or could not interpret uploader.value structure.")
            print("uploader.value type:", type(val), "content repr:", repr(val)[:200])
            return
        # use the first uploaded item
        filename, raw = items[0]
        if raw is None:
            print("Uploaded content is empty for", filename)
            return

        # decode bytes robustly (uses your earlier decode_bytes_to_rgb)
        img_rgb = decode_bytes_to_rgb(raw)
        if img_rgb is None:
            print("Failed to decode the uploaded file as an image. Saved raw content to bad_downloads for inspection.")
            return

        # display image
        plt.figure(figsize=(4,4))
        plt.imshow(img_rgb)
        plt.axis('off')
        plt.title(f"Uploaded: {filename}")
        plt.show()
        preds = predict_image_rgb(img_rgb, top_k=3)
        print("Top predictions:")
        for rank, label, conf in preds:
            print(f" - {label}  ({conf:.2%})")

btn.on_click(on_predict_clicked)
ui = VBox([HBox([uploader, btn]), status, out])
display(ui)

def save_uploaded_file(dest_folder="uploaded_images"):
    if len(uploader.value) == 0:
        print("No uploaded file to save.")
        return None
    os.makedirs(dest_folder, exist_ok=True)
    uploaded_name = list(uploader.value.keys())[0]
    raw = uploader.value[uploaded_name]['content']
    out_path = os.path.join(dest_folder, uploaded_name)
    with open(out_path, "wb") as f:
        f.write(raw)
    print("Saved to:", out_path)
    return out_path